# Flax to Axon - Interactive Tool

```elixir
Mix.install([
  {:axon, "~> 0.6.1"},
  {:stream_data, "~> 1.1"},
  {:nx, "~> 0.7.2"},
  {:safetensors, "~> 0.1.3"},
  {:kino, "~> 0.12.3"},
  {:langchain, "~> 0.2.0"}
])

asdf_dir = "#{__DIR__}/.asdf"

unless File.exists?(asdf_dir) do
  {_, 0} =
    System.cmd("git", [
      "clone",
      "https://github.com/asdf-vm/asdf.git",
      asdf_dir,
      "--branch",
      "v0.14.0"
    ])
end

asdf = "#{asdf_dir}/bin/asdf"
{_, 0} = System.cmd(asdf, ["plugin", "add", "python"], env: [{"ASDF_DATA_DIR", asdf_dir}])

{_, 0} =
  System.cmd(asdf, ["install", "python", "3.11.9"], env: [{"ASDF_DATA_DIR", "#{__DIR__}/.asdf"}])

asdf_python = Path.join([asdf_dir, "installs", "python", "3.11.9", "bin", "python"])

python_packages =
  ~w(
    safetensors
    torch
    transformers
    accelerate
    numpy
    datasets
    pillow
    flax
    jax
    jaxlib
  )

venv_dir = Path.join(__DIR__, "flax2axon_env")
{_, 0} = System.cmd(asdf_python, ["-m", "venv", "--copies", venv_dir])

python = Path.join([venv_dir, "bin", "python"])
pip = Path.join([venv_dir, "bin", "pip"])

{_, 0} = System.cmd(pip, ["install" | python_packages])

run_python = fn command, opts ->
  System.cmd(python, ["-c", command], opts)
end

data_dir = Path.join(__DIR__, "data")

unless File.exists?(data_dir), do: :ok = File.mkdir(data_dir)
```

## WARNING

> __This Livebook installs asdf, Python and some libraries in the directory of the livebook.__
> Modify the notebook setup if you don't want that.
> 
> It also __blindly runs LLM generated Elixir code__ using `Code.eval_string`. Don't use the `FixChain` if you don't want that.

## Introduction

You must set the `OPENAI_KEY` secret to your api key.

```elixir
api_key = System.get_env("LB_OPENAI_KEY")
```

### Goals

* (Semi-) Automatically convert Flax models to Axon (from `transformers`/`diffusers`)
* Verify that models compute same results for same inputs

For now, we consider only Flax (linen) because it's similar to Axon and should be easier than PyTorch or TensorFlow

<!-- livebook:{"break_markdown":true} -->

```mermaid
flowchart TD
    Input[Read Flax File]
    Classes[Split into classes]

    subgraph each_class[for each class]
      subgraph conversion[Convert into Axon]
        Convert[Convert using LLM instructions]
        Replace[Replace previously \n converted classes \n with Axon function]
      end
      subgraph verify[Verify same results]
        direction TB
        Generate[Generate input and params in Elixir]
        Compute_axon[Compute results in Axon]
        Safetensors[Save everything in safetensors]
        Load[Load safetensors in Python]
        Compute_flax[Compute results in Flax]
        Compare[Compare outputs for inputs]
      end

      Store[Store resulting Axon function]
    end


    Input-->Classes-->each_class

    Convert-->Replace
    Convert-->Convert
    conversion-->verify

    Generate-->Compute_axon-->Safetensors-->Load-->Compute_flax-->Compare

    verify-->Store
```

```elixir
transformers_path = Path.join(venv_dir, "lib/python3.11/site-packages/transformers")
resnet_flax_path = Path.join(transformers_path, "models/resnet/modeling_flax_resnet.py")

{:ok, resnet_input} = File.read(resnet_flax_path)
```

## Get inputs

```elixir
input = resnet_input
```

We get the individual classes

```elixir
input_classes = fn input ->
[_ | classes] = String.split(input, "\nclass ")
  for class <- classes, do: "class #{class}"
end
```

```elixir
extract_names = fn flax_code ->
  [flax_model_name | _] = String.split(flax_code, "(")
  flax_model_name = String.trim_leading(flax_model_name, "class ")
  axon_model_function_name = Macro.underscore(flax_model_name)
  {flax_model_name, axon_model_function_name}
end
```

Might need to figure out which classes depend on which other classes. Then, we do the following for each of them.

## Conversion

```elixir
alias LangChain.Chains.LLMChain
alias LangChain.ChatModels.ChatOpenAI
alias LangChain.Message
```

Define system messages to make this work better.

```elixir
system_messages =
  [
    """
    You are an expert in machine learning frameworks.
    You help converting models from Python code in Flax linen framework to Elixir code in the Axon framework.
    """,
    """
    You will do this by following instructions step by step.
    """,
    """
    I will provide you with the model code and an instruction in the following format:
    INSTRUCTION: here is the instruction you perform
    MODEL: here is the model code you will modify
    """,
    """
    For each of the following instructions, reply only with the modified code of the model.
    Do NOT include any other content or comments.
    """,
    """
    Perform ONLY the action the instruction asks you to do.
    """,
    """
    In case you don't change anything return ONLY the unchanged model code.
    """
  ]
  |> Enum.map(&Message.new_system!/1)
```

#### Conversion Tables

<!-- livebook:{"break_markdown":true} -->

Created using ChatGPT and refining format.

<!-- livebook:{"break_markdown":true} -->

##### Layers

Prompt:

Fetch the documentation about layers in Flax linen from here: https://flax.readthedocs.io/en/latest/api_reference/flax.linen/layers.html

Build a separate markdown table for each of the layers in Flax linen and the corresponding layer in Axon.
Each table should have two rows:
First row: shows the Flax linen layer in the first column, then a column for each parameter it takes. Prefix the linen layer with `nn.`
 Second row: shows the corresponding Axon layer in the first column, then the corresponding Axon parameter to each of the Flax linen parameters. Prefix the Axon layer with `Axon.Layer.`

If there is no corresponding layer, or no corresponding parameter, add a "-" instead.

Here an example for the Conv layer of Flax linen:

|      |           |          |             |         |         |       |          |                    |
| ---- | --------- | -------- | ----------- | ------- | ------- | ----- | -------- | ------------------ |
| Flax | nn.Conv   | features | kernel_size | strides | padding | dtype | use_bias | kernel_init        |
| Axon | Axon.conv | units    | kernel_size | strides | padding | -     | use_bias | kernel_initializer |

```elixir
conversion_layers =
  """
  ### Conv Layer

  |          | Layer     | features | kernel_size | strides | padding | dtype | use_bias | kernel_init        |
  | -------- | --------- | -------- | ----------- | ------- | ------- | ----- | -------- | ------------------ |
  | **Flax** | nn.Conv   | features | kernel_size | strides | padding | dtype | use_bias | kernel_init        |
  | **Axon** | Axon.conv | units    | kernel_size | strides | padding | -     | use_bias | kernel_initializer |

  ### Dense Layer

  |          | Layer      | features | use_bias | kernel_init        |
  | -------- | ---------- | -------- | -------- | ------------------ |
  | **Flax** | nn.Dense   | features | use_bias | kernel_init        |
  | **Axon** | Axon.dense | units    | use_bias | kernel_initializer |

  ### Dropout Layer

  |          | Layer        | rate |
  | -------- | ------------ | ---- |
  | **Flax** | nn.Dropout   | rate |
  | **Axon** | Axon.dropout | rate |

  ### BatchNorm Layer

  |          | Layer           | use_running_average | axis | momentum | epsilon | dtype |
  | -------- | --------------- | ------------------- | ---- | -------- | ------- | ----- |
  | **Flax** | nn.BatchNorm    | use_running_average | axis | momentum | epsilon | dtype |
  | **Axon** | Axon.batch_norm | -                   | axis | momentum | epsilon | -     |

  ### LayerNorm Layer

  |          | Layer           | axis | epsilon | dtype |
  | -------- | --------------- | ---- | ------- | ----- |
  | **Flax** | nn.LayerNorm    | axis | epsilon | dtype |
  | **Axon** | Axon.layer_norm | axis | epsilon | -     |

  ### Relu Layer

  |          | Layer     |
  | -------- | --------- |
  | **Flax** | nn.relu   |
  | **Axon** | Axon.relu |

  ### Sigmoid Layer

  |          | Layer        |
  | -------- | ------------ |
  | **Flax** | nn.sigmoid   |
  | **Axon** | Axon.sigmoid |

  ### Tanh Layer

  |          | Layer     |
  | -------- | --------- |
  | **Flax** | nn.tanh   |
  | **Axon** | Axon.tanh |

  ### MaxPool Layer

  |          | Layer         | window_shape | strides | padding |
  | -------- | ------------- | ------------ | ------- | ------- |
  | **Flax** | nn.max_pool   | window_shape | strides | padding |
  | **Axon** | Axon.max_pool | kernel_size  | strides | padding |

  ### AvgPool Layer

  |          | Layer         | window_shape | strides | padding |
  | -------- | ------------- | ------------ | ------- | ------- |
  | **Flax** | nn.avg_pool   | window_shape | strides | padding |
  | **Axon** | Axon.avg_pool | kernel_size  | strides | padding |

  ### GlobalAvgPool Layer

  |          | Layer                |
  | -------- | -------------------- |
  | **Flax** | nn.global_avg_pool   |
  | **Axon** | Axon.global_avg_pool |

  ### Flatten Layer

  |          | Layer        |
  | -------- | ------------ |
  | **Flax** | nn.Flatten   |
  | **Axon** | Axon.flatten |
  """

Kino.Markdown.new(conversion_layers)
```

#### Initializers

Prompt:

Fetch the documentation about initializers in Axon from here: https://hexdocs.pm/axon/Axon.Initializers.html  
Fetch the documentation about initializers in Flax linen from here: https://flax.readthedocs.io/en/latest/api_reference/flax.linen/initializers.html

Build a separate markdown table for each of the initializers in Flax linen and the corresponding initializer in Axon.
Each table should have two rows:
First row: shows the Flax linen initializer in the first column, then a column for each parameter it takes. Prefix the linen initializer with `nn.`
 Second row: shows the corresponding Axon initializer in the first column, then the corresponding Axon parameter to each of the Flax linen parameters. Prefix the Axon initializer with `Axon.Layer.`

If there is no corresponding initializer, or no corresponding parameter, add a "-" instead.

Here an example for the `initializers.variance_scaling` of Flax linen:

|      |                                  |       |      |              |         |          |            |       |
| ---- | -------------------------------- | ----- | ---- | ------------ | ------- | -------- | ---------- | ----- |
| Flax | nn.initializers.variance_scaling | scale | mode | distribution | in_axis | out_axis | batch_axis | dtype |

| Axon  | Axon.Initializers.variance_scaling | scale | mode | distribution |

```elixir
conversion_initializers =
  """
  ### Variance Scaling

  |      |                                    |       |      |              |         |          |            |       |
  | ---- | ---------------------------------- | ----- | ---- | ------------ | ------- | -------- | ---------- | ----- |
  | Flax | nn.initializers.variance_scaling   | scale | mode | distribution | in_axis | out_axis | batch_axis | dtype |
  | Axon | Axon.Initializers.variance_scaling | scale | mode | distribution | -       | -        | -          | -     |

  ### Glorot Normal

  |      |                                 |       |
  | ---- | ------------------------------- | ----- |
  | Flax | nn.initializers.glorot_normal   | dtype |
  | Axon | Axon.Initializers.glorot_normal | -     |

  ### Glorot Uniform

  |      |                                  |       |
  | ---- | -------------------------------- | ----- |
  | Flax | nn.initializers.glorot_uniform   | dtype |
  | Axon | Axon.Initializers.glorot_uniform | -     |

  ### Lecun Normal

  |      |                                |       |
  | ---- | ------------------------------ | ----- |
  | Flax | nn.initializers.lecun_normal   | dtype |
  | Axon | Axon.Initializers.lecun_normal | -     |

  ### Lecun Uniform

  |      |                                 |       |
  | ---- | ------------------------------- | ----- |
  | Flax | nn.initializers.lecun_uniform   | dtype |
  | Axon | Axon.Initializers.lecun_uniform | -     |

  ### Orthogonal

  |      |                              |              |
  | ---- | ---------------------------- | ------------ |
  | Flax | nn.initializers.orthogonal   | scale        |
  | Axon | Axon.Initializers.orthogonal | distribution |

  ### Constant

  |      |                          |       |
  | ---- | ------------------------ | ----- |
  | Flax | nn.initializers.constant | value |
  | Axon | Axon.Initializers.full   | value |

  ### Normal

  |      |                          |      |        |
  | ---- | ------------------------ | ---- | ------ |
  | Flax | nn.initializers.normal   | mean | stddev |
  | Axon | Axon.Initializers.normal | mean | scale  |

  ### Uniform

  |      |                           |        |        |
  | ---- | ------------------------- | ------ | ------ |
  | Flax | nn.initializers.uniform   | minval | maxval |
  | Axon | Axon.Initializers.uniform | -      | scale  |

  ### Identity

  |      |                            |
  | ---- | -------------------------- |
  | Flax | nn.initializers.identity   |
  | Axon | Axon.Initializers.identity |

  ### Ones

  |      |                        |
  | ---- | ---------------------- |
  | Flax | nn.initializers.ones   |
  | Axon | Axon.Initializers.ones |

  ### Zeros

  |      |                         |
  | ---- | ----------------------- |
  | Flax | nn.initializers.zeros   |
  | Axon | Axon.Initializers.zeros |
  """

Kino.Markdown.new(conversion_initializers)
```

#### Activation Functions

Prompt:

Fetch the documentation about activations in Axon from here: https://hexdocs.pm/axon/Axon.Activations.html  
Fetch the documentation about activations in Flax linen from here: https://flax.readthedocs.io/en/latest/api_reference/flax.linen/activation_functions.html

Build a separate markdown table for each of the activations in Flax linen and the corresponding activation in Axon.
Each table should have two rows:
First row: shows the Flax linen activation in the first column, then a column for each parameter it takes. Prefix the linen activation with `nn.`
 Second row: shows the corresponding Axon activation in the first column, then the corresponding Axon parameter to each of the Flax linen parameters. Prefix the Axon activation with `Axon.Activations.`

If there is no corresponding activation, or no corresponding parameter, add a "-" instead.

Here an example for `activation.softmax` of Flax linen:

|      |                          |      |       |         |
| ---- | ------------------------ | ---- | ----- | ------- |
| Flax | nn.activation.softmax    | axis | where | initial |
| Axon | Axon.Activations.softmax | axis | -     | -       |

```elixir
conversion_activations =
  """
  ### Softmax

  |      |                          |      |       |         |
  | ---- | ------------------------ | ---- | ----- | ------- |
  | Flax | nn.softmax               | axis | where | initial |
  | Axon | Axon.Activations.softmax | axis | -     | -       |

  ### ReLU

  |      |                       |
  | ---- | --------------------- |
  | Flax | nn.relu               |
  | Axon | Axon.Activations.relu |

  ### Leaky ReLU

  |      |                             |                |
  | ---- | --------------------------- | -------------- |
  | Flax | nn.leaky_relu               | negative_slope |
  | Axon | Axon.Activations.leaky_relu | alpha          |

  ### Sigmoid

  |      |                          |
  | ---- | ------------------------ |
  | Flax | nn.sigmoid               |
  | Axon | Axon.Activations.sigmoid |

  ### Tanh

  |      |                       |
  | ---- | --------------------- |
  | Flax | nn.tanh               |
  | Axon | Axon.Activations.tanh |

  ### GELU

  |      |                       |             |
  | ---- | --------------------- | ----------- |
  | Flax | nn.gelu               | approximate |
  | Axon | Axon.Activations.gelu | -           |

  ### ELU

  |      |                      |       |
  | ---- | -------------------- | ----- |
  | Flax | nn.elu               | alpha |
  | Axon | Axon.Activations.elu | alpha |

  ### SELU

  |      |                       |
  | ---- | --------------------- |
  | Flax | nn.selu               |
  | Axon | Axon.Activations.selu |

  ### Softplus

  |      |                           |
  | ---- | ------------------------- |
  | Flax | nn.softplus               |
  | Axon | Axon.Activations.softplus |

  ### Swish

  |      |                        |
  | ---- | ---------------------- |
  | Flax | nn.swish               |
  | Axon | Axon.Activations.swish |

  ### Log Softmax

  |      |                              |      |       |         |
  | ---- | ---------------------------- | ---- | ----- | ------- |
  | Flax | nn.log_softmax               | axis | where | initial |
  | Axon | Axon.Activations.log_softmax | axis | -     | -       |
  """

Kino.Markdown.new(conversion_activations)
```

```elixir
conversion_messages =
  [
    conversion_layers,
    conversion_initializers,
    conversion_activations
  ]
  |> Enum.map(&Message.new_system!/1)
```

Define the langchain

```elixir
defmodule ConversionChain do
  def new!(api_key, system_messages, conversion_messages) do
    {:ok, chain, _response} =
      %{
        llm:
          ChatOpenAI.new!(%{
            model: "gpt-4o",
            api_key: api_key,
            seed: 0
          })
      }
      |> LLMChain.new!()
      |> LLMChain.add_messages(system_messages)
      |> LLMChain.add_messages(conversion_messages)
      |> LLMChain.run()

    chain
  end
end
```

```elixir
send_user_message = fn chain, message ->
  chain
  |> LLMChain.add_message(Message.new_user!(message))
  |> LLMChain.run()
end
```

### Detailed instructions how to convert the model

```elixir
conversion_instructions = [
  """
  If there is a setup function, replace the calls to the stored methods in __call__ with the actual Flax layer, including the parameters.
  """,
  """
  If there are attributes, move them to the __call__ function as parameters and replace all the references of the attributes with the function parameters.
  """,
  """
  In the __call__ function, move all additional parameters when calling the layers to the initialization of the layers. Each layer should be called with a single argument.
  """,
  """
  Extract loops to a seperate function, transform this function according to our rules. Plug the function into the pipeline.
  """,
  """
  Replace the Flax layers with the corresponding Axon layers according to our conversion table. Return only the Elixir code for the model. Take into account the parameters in the first parenthesis. Replace initializer functions with the corresponding Axon functions. Follow these rules to replace activation functions: If there is an activation parameter, and the code makes use of ACT2FN[activation], replace that with Axon.activation(activation). If there is an actual activation function called, replace it with Axon's activation function according to the conversion table. Replace all = for arguments with :
  """,
  """
  Remove the return keyword at the end of the __call__ function. Keep what would be returned on this line.
  """,
  """
   Wrap the Axon model in a function that takes all the required parameters from the __call__ function
  - name the function corresponding to the class name, but snake case.
  - take the same arguments as the __call__ function
  - remove the self argument
  - remove the dtype argument
  - remove the type specs if present
  - wrap the function in do ... end
  """,
  """
  Remove all `use ...` directives from the Elixir code.
  """,
  """
  Check if the function is valid Elixir code. Otherwise, fix all issues by converting Python expressions to Elixir expressions. E.g. // corresponds to div, scientific notation like 1e-05 needs a decimal point in Elixir 1.0e-05.
  """
]
```

```elixir
instruction_message = fn instruction, model ->
  """
  INSTRUCTION: #{instruction}
  MODEL:
  #{model}
  """
end
```

### Extra chain for fixing general Elixir issues at the end

````elixir
defmodule FixChain do
  def new!(api_key) do
    {:ok, chain, _response} =
      %{
        llm:
          ChatOpenAI.new!(%{
            model: "gpt-4o",
            api_key: api_key,
            seed: 0
          })
      }
      |> LLMChain.new!()
      |> LLMChain.add_message(
        Message.new_system!("You are an expert in Python, Flax, Elixir and Axon.")
      )
      |> LLMChain.run()

    chain
  end

  defp fix_instruction(code) do
    """
    Fix this Elixir code according to the error message.
    Reply ONLY with the modified Elixir code.
    If you don't modify anything reply with the unchanged code.
    #{code}
    """
  end

  def fix_model(chain, model) do
    fix_instruction = fix_instruction(model)

    {:ok, _chain, response} =
      chain
      |> LLMChain.add_message(Message.new_user!(fix_instruction))
      |> LLMChain.run()

    response.content
  end

  def maybe_fix_model(model, chain, retries) do
    if retries == 0 do
      {:error, model}
    else
      dbg("trying to fix #{retries}")

      model =
        model
        |> String.trim_leading("```elixir")
        |> String.trim_trailing("```")

      dbg(model)
      
      try do
        ## check that it's valid code 
        Code.eval_string(model, [], __ENV__)
      rescue
        _ -> fix_model(chain, model) |> maybe_fix_model(chain, retries - 1)
      else
        _ -> {:ok, model}
      end
    end
  end
end
````

Build the model

```elixir
convert_model = fn conversion_chain, fix_chain, model ->
  {_, converted_model} =
    for instruction <- conversion_instructions, reduce: {conversion_chain, model} do
      {c, m} ->
        {:ok, updated_chain, response} =
          send_user_message.(c, instruction_message.(instruction, m))

        {updated_chain, response.content}
    end

  case FixChain.maybe_fix_model(converted_model, fix_chain, 3) do
    {:ok, model} -> {:ok, model}
    {:error, model} -> {:conversion_failed, model}
  end
end
```

```elixir
apply_model_fn = fn module_name, model_fn_name, args ->  
  apply(module_name, String.to_atom(model_fn_name), args)  
end
```

## Verify

### Check that Python installation works

```elixir
IO.puts("Python is here: #{python}")
{_, 0} = run_python.("print('hello from Python')", [])
```

Define paths for `safetensors` files, we will use those to work on the same numbers in Python and Elixir.

```elixir
safetensor_files = fn dir, name ->
  {Path.join(dir, "#{name}_params_axon.safetensors"),
   Path.join(dir, "#{name}_params_flax.safetensors"),
   Path.join(dir, "#{name}_test_data_axon.safetensors"),
   Path.join(dir, "#{name}_test_data_flax.safetensors")}
end
```

```elixir
defmodule ParamsUtils do
  def flatten_keys(%{} = params) do
    for key <- Map.keys(params) do
      prefixed_keys(params[key], key)
    end
    |> List.flatten()
  end

  defp prefixed_keys(%Nx.Tensor{}, key), do: key

  defp prefixed_keys(%{} = params, prefix) do
    for key <- Map.keys(params) do
      prefixed_keys(params[key], "#{prefix}.#{key}")
    end
  end

  def get_from_flattened_key(params, flattened_key) do
    keys = String.split(flattened_key, ".")

    for key <- keys, reduce: params do
      acc -> acc[key]
    end
  end

  def unflatten_and_put(params, flattened_key, value) do
    single_param_map = flattened_map(flattened_key, value)

    merge_recursive(params, single_param_map)
  end

  def merge_recursive(%{} = map1, %{} = map2) do
    Map.merge(map1, map2, fn _k, m1, m2 -> merge_recursive(m1, m2) end)
  end

  defp flattened_map(flattened_key, value) do
    case String.split(flattened_key, ".", parts: 2) do
      [key] -> %{key => value}
      [key, other_keys] -> %{key => flattened_map(other_keys, value)}
    end
  end
end
```

Must find some way to map params (using LLM?)

```elixir
get_param_mapping = fn ->
  param_mapping = %{
    "batch_norm_0.beta" => "params.normalization.bias",
    "batch_norm_0.gamma" => "params.normalization.scale",
    "batch_norm_0.mean" => "batch_stats.normalization.mean",
    "batch_norm_0.var" => "batch_stats.normalization.var",
    "conv_0.kernel" => "params.convolution.kernel"
  }
end
```

Write `safetensors` files for Axon and Flax params.

```elixir
save_params = fn params, param_mapping, axon_params_path, flax_params_path ->
  axon_params =
    for {axon_key, _} <- param_mapping, into: %{} do
      {axon_key, ParamsUtils.get_from_flattened_key(params, axon_key)}
    end

  flax_params =
    for {axon_key, flax_key} <- param_mapping, into: %{} do
      {flax_key, ParamsUtils.get_from_flattened_key(params, axon_key)}
    end

  Safetensors.write!(axon_params_path, axon_params)
  Safetensors.write!(flax_params_path, flax_params)
end
```

```elixir
model_string_fn = fn model_code ->
  """
  defmodule ModelTest do
  #{model_code}
  end
  """
end
```

### Run tests with random data

<!-- livebook:{"break_markdown":true} -->

First in Axon.

```elixir
run_axon_and_save = fn predict_fn, params, input_shape, path ->
  input_data =
    for dim <- Enum.reverse(Tuple.to_list(input_shape)), reduce: StreamData.float() do
      acc -> StreamData.list_of(acc, length: dim)
    end

  test_data =
    for i <- 0..100 do
      input =
        input_data
        |> Enum.take(1)
        |> hd
        |> Nx.tensor()

      input_name = "input_#{i}"
      output_name = "output_#{i}"

      output = predict_fn.(params, input)

      [{input_name, input}, {output_name, output}]
    end
    |> List.flatten()
    |> Map.new()

  Safetensors.write!(path, test_data)
end
```

Then in Flax.

```elixir
# need path for import, e.g. transformers.models.resnet.modeling_flax_resnet
run_flax_and_save = fn module, module_args, input_path, output_path, params_path ->
  test_flax =
    """
    import jax
    from typing import Any, Callable, Sequence
    from jax import random, numpy as jnp
    import flax
    from flax import linen as nn

    from functools import partial
    from typing import Optional, Tuple

    from safetensors import safe_open
    from safetensors.flax import save_file

    from transformers.models.resnet.modeling_flax_resnet import #{module}

    def unflatten_dict(d, sep='.'):
      result = {}
      for key, value in d.items():
          parts = key.split(sep)
          node = result
          for part in parts[:-1]:
              node = node.setdefault(part, {})
          node[parts[-1]] = value
      return result

    tensors = {}
    with safe_open("#{input_path}", framework="flax") as f:
        for k in f.keys():
            tensors[k] = f.get_tensor(k)

    model = #{module}(#{module_args})
    key = random.key(0)


    params = {}
    with safe_open("#{params_path}", framework="flax") as f:
        for k in f.keys():
            params[k] = f.get_tensor(k)

    params = unflatten_dict(params)

    out_tensors = tensors.copy()
    input_keys = [key for key in tensors.keys() if key.startswith("input")]
    for input_key in input_keys:  
      input = tensors[input_key]

      output = model.apply(params, input)
      output_key = input_key.replace("input", "output")

      out_tensors[output_key] = output

    save_file(out_tensors, "#{output_path}")
    """

  run_python.(test_flax, [])
end
```

Verify that we get same results.

```elixir
assert_all_close = fn left, right ->
  atol = 1.0e-4
  rtol = 1.0e-4

  equals =
    left
    |> Nx.all_close(right, atol: atol, rtol: rtol)
    |> Nx.backend_transfer(Nx.BinaryBackend)

  equals == Nx.tensor(1, type: :u8, backend: Nx.BinaryBackend)
end

same_result? = fn axon_result, flax_result ->
  assert_all_close.(axon_result, flax_result)
end

verification_results = fn axon_path, flax_path ->
  axon_data = Safetensors.read!(axon_path)
  flax_data = Safetensors.read!(flax_path)

  for output_key <- Map.keys(axon_data), String.starts_with?(output_key, "output"), into: %{} do
    input_key = String.replace(output_key, "output", "input")

    got_same? = same_result?.(axon_data[output_key], flax_data[output_key])

    {output_key,
     %{
       same_result?: got_same?,
       input: axon_data[input_key],
       axon_output: axon_data[output_key],
       flax_output: flax_data[output_key]
     }}
  end
end
```

```elixir
build_model_fn = fn model_code, axon_function_name ->
  ## find set of arguments we need
  out_channels = 2
  kernel_size = 3
  stride = 1
  activation = :relu
  args = [Axon.input(""), out_channels, kernel_size, stride, activation]
  
  model = model_string_fn.(model_code)
  Code.eval_string(model, [], __ENV__)
  
  model = apply_model_fn.(ModelTest, axon_function_name, args)

  Axon.build(model)
end
```

```elixir
get_params = fn init_fn, input_shape, input_type ->
  # get input_shape and input_type
  init_fn.(Nx.template(input_shape, input_type), %{})
end
```

```elixir
verify_model = fn model_code, data_dir, flax_model_name, axon_function_name ->
  # build model
  {init_fn, predict_fn} = build_model_fn.(model_code, axon_function_name)

  # get params and param mapping
  input_shape = {1, 3, 3, 3}
  input_type = :f32

  {:ok, params} = get_params.(init_fn, input_shape, input_type)
  param_mapping = get_param_mapping.()

  # paths for safetensors files
  {axon_params_path, flax_params_path, axon_path, flax_path} =
    safetensor_files.(data_dir, axon_function_name)

  # save params
  save_params.(params, param_mapping, axon_params_path, flax_params_path)

  # run axon, save data
  run_axon_and_save.(predict_fn, params, input_shape, axon_path)

  # run flax, save data
  flax_model_args = 3
  run_flax_and_save.(flax_model_name, flax_model_args, axon_path, flax_path, flax_params_path)

  # check if results are the same 
  results = verification_results.(axon_path, flax_path)

  if Enum.all?(results) do
    {:ok, model_code, results}
  else
    {:verification_failed, model_code, results}
  end
end
```

## Run it all

```elixir
conversion_chain = ConversionChain.new!(api_key, system_messages, conversion_messages)
fix_chain = FixChain.new!(api_key)
```

```elixir
model = input_classes.(input) |> Enum.at(1) 
```

```elixir
import Kino.Shorts

next = Kino.Control.button("Run Instruction")

stream = Kino.Control.tagged_stream(next: next)

old_frame = frame()
new_frame = frame()

instruction_frame = frame()

instruction = Enum.at(conversion_instructions, 0, "return unchanged model")
instruction_length = Enum.count(conversion_instructions)

Kino.Frame.render(
  instruction_frame,
  Kino.Markdown.new("[1/#{instruction_length}] " <> instruction)
)

model_text = Kino.Input.textarea("Original model", default: model)

layout =
  tabs(
    Conversion:
      Kino.Layout.grid(
        [
          markdown("### Next LLM instruction"),
          text(""),
          instruction_frame,
          next,
          markdown("### Most recent version"),
          markdown("### Next LLM input"),
          old_frame,
          new_frame
        ],
        boxed: true,
        columns: 2
      ),
    Verification: text("verify")
  )

Kino.nothing()
```

```elixir
Kino.listen(stream, {conversion_chain, model_text, 0}, fn event, {chain, model_input, i} ->
  instruction = Enum.at(conversion_instructions, i, "return unchanged model")
  Kino.Frame.render(instruction_frame, Kino.Markdown.new("[#{i}/#{instruction_length}] " <> instruction))

  old_text = Kino.Input.read(model_input)
  Kino.Frame.render(old_frame, Kino.Markdown.new(old_text))

  new_text = Kino.Input.read(model_input)
  {:ok, updated_chain, response} =
    send_user_message.(chain, instruction_message.(instruction, new_text))

  new_text_input = Kino.Input.textarea("model_input", default: response.content, monospace: true)
  Kino.Frame.render(new_frame, new_text_input)

  i =
    case event do
      {:next, _e} -> i + 1
      {:back, _e} -> i - 1
    end

  {:cont, {updated_chain, new_text_input, i}}
end)
```

```elixir
Kino.render(model_text)
layout
```

```elixir
converted_model = Kino.Input.read(new_frame)
  case FixChain.maybe_fix_model(converted_model, fix_chain, 3) do
    {:ok, model} -> {:ok, model}
    {:error, model} -> {:conversion_failed, model}
  end
```

<!-- livebook:{"offset":32171,"stamp":{"token":"XCP.6kLthxEbflapBwEELl6biioeh9KJzkKdCrfVqrlRutZKExf4SkmL6ZHi26G-UsIdPlnhz3G1ljMjs3Dxn_OWbW8heMcFjREiDk4ICNHvral0geAr-g","version":2}} -->
